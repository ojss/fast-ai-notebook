{"cells":[{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"cell_id":"3dd10cf7-fe0e-4e8c-b515-44d15fe4c962"}},{"cell_type":"code","metadata":{"cell_id":"03248080-d5ab-43d8-9a25-12f123622103"},"source":"%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline","outputs":[{"name":"stdout","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n","output_type":"stream"}]},{"cell_type":"code","source":"#export\nfrom exp.nb_11a import *","metadata":{"tags":[],"cell_id":"3bf486d6-0663-4ba3-a6f6-34521d1fefae"},"outputs":[]},{"cell_type":"markdown","source":"## Data Setup","metadata":{"cell_id":"23ce1e7c-75c7-4862-ab40-18c8061516b2"}},{"cell_type":"code","metadata":{"cell_id":"0f050cac-fcbd-4a6a-8e5a-dd079a69a676"},"source":"path = datasets.untar_data(datasets.URLs.IMDB)","outputs":[{"name":"stdout","text":"Downloading https://s3.amazonaws.com/fast-ai-nlp/imdb.tgz\n","output_type":"stream"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"cell_id":"f8b1f06b-2464-4c37-8062-87cf7c1e79f9"},"source":"path.ls()","outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"[PosixPath('/home/jovyan/.fastai/data/imdb/tmp_lm'),\n PosixPath('/home/jovyan/.fastai/data/imdb/train'),\n PosixPath('/home/jovyan/.fastai/data/imdb/tmp_clas'),\n PosixPath('/home/jovyan/.fastai/data/imdb/README'),\n PosixPath('/home/jovyan/.fastai/data/imdb/imdb.vocab'),\n PosixPath('/home/jovyan/.fastai/data/imdb/test'),\n PosixPath('/home/jovyan/.fastai/data/imdb/unsup')]"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"8e757b48-285c-4bcf-a1a1-d3988da15ce5"},"source":"#export\ndef read_file(fn):\n    with open(fn, 'r', encoding='utf-8') as f:\n        return f.read()\n\nclass TextList(ItemList):\n    @classmethod\n    def from_files(cls, path, extensions='.txt', recurse=True, include=None, **kwargs):\n        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n    \n    def get(self, i):\n        if isinstance(i, Path):\n            return read_file(i)\n        return i\n    ","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"2b6c89c2-9b39-4f50-859b-eeceb8174152"},"source":"il = TextList.from_files(path, include=['train', 'test', 'unsup'])","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"3a8c321a-5913-4079-9346-1542abd8d129"},"source":"len(il.items)","outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"100000"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"2904804e-824a-4285-8d0f-126f37b4dc20"},"source":"txt = il[0]\ntxt","outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"'I grew up on the \\'Superman II\\' theatrical version (\"S2T\") and as a kid, I loved it more than Part I since not only did it contain more Superman and three Superman-type villains, it started off with a bang \\x96 the best Clark Kent to Superman transformations and rescue scenes. Kids no longer had to impatiently wait for Superman to appear on screen, as in part I. Now as an adult, I can see how the mighty had fallen with S2T (See: my review.) I\\'ve always heard of the back-story on how they prematurely and unjustifiably fired the original\\'s director, Richard Donner from part II. (It must have been a rarity back then to film two separate movies simultaneously, now it\\'s common: \\'Back to the Future\\' and \\'Matrix\\' 2 & 3 for example.) Unfortunately, after finally seeing the Richard Donner Cut (or, \"S2RD\") I still can\\'t fully recommend it. Gone, was the great Superman change scene, the entire Paris rescue, as was the wonderful recap of part I in S2T\\'s opening. In fact, they all but wrote the words: \"Previously on Superman\\x85\" in S2RD. The special effects weren\\'t great in either Part I or S2T , but S2RD, they were mostly downright laughable \\x96 such as Lois falling from the Daily Planet window. I will admit, some new scenes worked and some they took out were welcomed departures, such as any scene in the \"honeymoon suite.\" Overall, if you grew up on S2T as I did, and loved it as a child \\x96 not nitpicking as I do as an adult, you should absolutely see S2RD as it\\'s almost a brand new childhood experience with dozens of new scenes. (Spoiler alert) Unfortunately, the worst change comes last: gone was also the weird amnesia kiss from S2T replaced with the exact same ending as \\'I.\\' This is not only a lazy, unoriginal copout, it doesn\\'t make sense on why Clark would go back to that diner, if those events never actually happened. And will he continue to \"turn back time\" for every confrontation?'"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"fa92d502-4cfa-4ccb-802f-f89c1dffc6e9"},"source":"sd = SplitData.split_by_func(il, partial(random_splitter, p_valid=0.1))","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"5041de2a-89b8-45c1-ba70-f9e2087be020"},"source":"sd","outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"SplitData\nTrain: TextList (89732 items)\n[PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/10055_3.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/461_1.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/12197_2.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/11418_4.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/1578_1.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/5495_3.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/11696_4.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/9568_2.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/2688_1.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/11800_4.txt')...]\nPath: /home/jovyan/.fastai/data/imdb\nValid: TextList (10268 items)\n[PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/4849_1.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/2797_1.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/7745_1.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/11441_4.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/4792_3.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/7093_1.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/4844_2.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/8677_2.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/10141_2.txt'), PosixPath('/home/jovyan/.fastai/data/imdb/train/neg/9084_1.txt')...]\nPath: /home/jovyan/.fastai/data/imdb"},"metadata":{}}]},{"cell_type":"markdown","source":"## Tokenizing","metadata":{"cell_id":"bbe13a5d-cfaa-43d2-919c-53ed435111c0"}},{"cell_type":"markdown","source":"We need to tokenize the dataset first, which is splitting a sentence in individual tokens. Those tokens are the basic words or punctuation signs with a few tweaks: don't for instance is split between do and n't. We will use a processor for this, in conjunction with the [spacy library](https://spacy.io/).","metadata":{"cell_id":"6388478f-7829-4d0b-b24d-8431b7cdfa12"}},{"cell_type":"code","metadata":{"cell_id":"bf514ca2-ad37-4657-a950-4cac7d44627c"},"source":"#export\nimport spacy\nimport html","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"64a52a7f-9f05-4a9d-bc1b-c9755fda4ea1"},"source":"#export\n# special tokens\nUNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ = \"xxunk xxpad xxbos xxeos xxrep xxwrep xxup xxmaj\".split()\n\ndef sub_br(t):\n    \"Replaces the <br /> by \\n\"\n    re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n    return re_br.sub(\"\\n\", t)\n\ndef spec_add_spaces(t):\n    \"Add spaces around / and #\"\n    return re.sub(r'([/#])', r' \\1 ', t)\n\ndef rm_useless_spaces(t):\n    \"Remove multiple spaces\"\n    return re.sub(' {2,}', ' ', t)\n\ndef replace_rep(t):\n    \"Replace repetitions at the character level: cccc -> TK_REP 4 c\"\n    def _replace_rep(m:Collection[str]) -> str:\n        c,cc = m.groups()\n        return f' {TK_REP} {len(cc)+1} {c} '\n    re_rep = re.compile(r'(\\S)(\\1{3,})')\n    return re_rep.sub(_replace_rep, t)\n    \ndef replace_wrep(t):\n    \"Replace word repetitions: word word word -> TK_WREP 3 word\"\n    def _replace_wrep(m:Collection[str]) -> str:\n        c,cc = m.groups()\n        return f' {TK_WREP} {len(cc.split())+1} {c} '\n    re_wrep = re.compile(r'(\\b\\w+\\W+)(\\1{3,})')\n    return re_wrep.sub(_replace_wrep, t)\n\ndef fixup_text(x):\n    \"Various messy things we've seen in documents\"\n    re1 = re.compile(r'  +')\n    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>',UNK).replace(' @.@ ','.').replace(\n        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n    return re1.sub(' ', html.unescape(x))\n    \ndefault_pre_rules = [fixup_text, replace_rep, replace_wrep, spec_add_spaces, rm_useless_spaces, sub_br]\ndefault_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"17775157-05c7-4cfa-9455-ff59bdb26152"},"source":"replace_rep('cccc')","outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"' xxrep 4 c '"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"43c0cf04-4cf1-4aec-ad34-1f4a603b9daf"},"source":"replace_wrep('word word word word word ')","outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"' xxwrep 5 word  '"},"metadata":{}}]},{"cell_type":"markdown","source":"These rules are applies after the tokenization on the list of tokens.","metadata":{"cell_id":"1106c253-ea8d-4aa0-aeee-f059a51df0a2"}},{"cell_type":"code","metadata":{"cell_id":"7ec29402-0da1-4aaf-8196-bb12b629522c"},"source":"#export\ndef replace_all_caps(x):\n    \"Replace tokens in ALL CAPS by their lower version and add `TK_UP` before.\"\n    res = []\n    for t in x:\n        if t.isupper() and len(t) > 1: res.append(TK_UP); res.append(t.lower())\n        else: res.append(t)\n    return res\n\ndef deal_caps(x):\n    \"Replace all Capitalized tokens in by their lower version and add `TK_MAJ` before.\"\n    res = []\n    for t in x:\n        if t == '': continue\n        if t[0].isupper() and len(t) > 1 and t[1:].islower(): res.append(TK_MAJ)\n        res.append(t.lower())\n    return res\n\ndef add_eos_bos(x): return [BOS] + x + [EOS]\n\ndefault_post_rules = [deal_caps, replace_all_caps, add_eos_bos]","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"3a43ab9c-e855-46bd-b474-6d9bf80dc56b"},"source":"replace_all_caps(['I', 'AM', 'SHOUTING'])","outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"['I', 'xxup', 'am', 'xxup', 'shouting']"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"554fbb98-e5a0-435f-ac91-13ada86f6ed2"},"source":"deal_caps(['My', 'name', 'is', 'Jeremy'])","outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"['xxmaj', 'my', 'name', 'is', 'xxmaj', 'jeremy']"},"metadata":{}}]},{"cell_type":"markdown","source":"Since tokenizing and applying those rules takes a bit of time, we'll parallelize it using `ProcessPoolExecutor` to go faster.","metadata":{"cell_id":"0be9f26f-4908-4fd8-ada5-74e004dfe559"}},{"cell_type":"code","metadata":{"cell_id":"c88b4959-8387-4d9b-b652-44e9dad1bf1e"},"source":"#export\nfrom spacy.symbols import ORTH\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef parallel(func, arr, max_workers=4):\n    if max_workers<2: results = list(progress_bar(map(func, enumerate(arr)), total=len(arr)))\n    else:\n        with ProcessPoolExecutor(max_workers=max_workers) as ex:\n            return list(progress_bar(ex.map(func, enumerate(arr)), total=len(arr)))\n    if any([o is not None for o in results]): return results","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"445a3ae7-feae-4dce-b654-26ce46e8712a"},"source":"#export\nclass TokenizeProcessor(Processor):\n    def __init__(self, lang=\"en\", chunksize=2000, pre_rules=None, post_rules=None, max_workers=4): \n        self.chunksize,self.max_workers = chunksize,max_workers\n        self.tokenizer = spacy.blank(lang).tokenizer\n        for w in default_spec_tok:\n            self.tokenizer.add_special_case(w, [{ORTH: w}])\n        self.pre_rules  = default_pre_rules  if pre_rules  is None else pre_rules\n        self.post_rules = default_post_rules if post_rules is None else post_rules\n\n    def proc_chunk(self, args):\n        i,chunk = args\n        chunk = [compose(t, self.pre_rules) for t in chunk]\n        docs = [[d.text for d in doc] for doc in self.tokenizer.pipe(chunk)]\n        docs = [compose(t, self.post_rules) for t in docs]\n        return docs\n\n    def __call__(self, items): \n        toks = []\n        if isinstance(items[0], Path): items = [read_file(i) for i in items]\n        chunks = [items[i: i+self.chunksize] for i in (range(0, len(items), self.chunksize))]\n        toks = parallel(self.proc_chunk, chunks, max_workers=self.max_workers)\n        return sum(toks, [])\n    \n    def proc1(self, item): return self.proc_chunk([item])[0]\n    \n    def deprocess(self, toks): return [self.deproc1(tok) for tok in toks]\n    def deproc1(self, tok):    return \" \".join(tok)","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"91882bd5-f687-4234-a3e6-5a1a485ab532"},"source":"tp = TokenizeProcessor()","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"ed727e70-4fb4-45ad-a365-cfe9226de4d3"},"source":"txt[:250]","outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"'I grew up on the \\'Superman II\\' theatrical version (\"S2T\") and as a kid, I loved it more than Part I since not only did it contain more Superman and three Superman-type villains, it started off with a bang \\x96 the best Clark Kent to Superman transformat'"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"de283409-53f1-4270-b4e0-f8aee954e410"},"source":"' • '.join(tp(il[:100])[0])[:400]","outputs":[{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "},"metadata":{},"output_type":"display_data"},{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"'xxbos • i • grew • up • on • the • \\' • xxmaj • superman • ii • \\' • theatrical • version • ( • \" • s2 • t • \" • ) • and • as • a • kid • , • i • loved • it • more • than • xxmaj • part • i • since • not • only • did • it • contain • more • xxmaj • superman • and • three • xxmaj • superman • - • type • villains • , • it • started • off • with • a • bang • \\x96 • the • best • xxmaj • clark • xxmaj • ken'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Numericalizing","metadata":{"cell_id":"2317af6a-bbaa-4404-bbd8-c727397d326c"}},{"cell_type":"code","metadata":{"cell_id":"de15de9d-1e06-4609-91f2-037c5c5c7d44"},"source":"#export\nimport collections\n\nclass NumericalizeProcessor(Processor):\n    def __init__(self, vocab=None, max_vocab=60000, min_freq=2): \n        self.vocab,self.max_vocab,self.min_freq = vocab,max_vocab,min_freq\n    \n    def __call__(self, items):\n        #The vocab is defined on the first use.\n        if self.vocab is None:\n            freq = Counter(p for o in items for p in o)\n            self.vocab = [o for o,c in freq.most_common(self.max_vocab) if c >= self.min_freq]\n            for o in reversed(default_spec_tok):\n                if o in self.vocab: self.vocab.remove(o)\n                self.vocab.insert(0, o)\n        if getattr(self, 'otoi', None) is None:\n            self.otoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.vocab)}) \n        return [self.proc1(o) for o in items]\n    def proc1(self, item):  return [self.otoi[o] for o in item]\n    \n    def deprocess(self, idxs):\n        assert self.vocab is not None\n        return [self.deproc1(idx) for idx in idxs]\n    def deproc1(self, idx): return [self.vocab[i] for i in idx]","outputs":[]},{"cell_type":"markdown","source":"When we do language modeling, we will infer the labels from the text during training, so there's no need to label. The training loop expects labels however, so we need to add dummy ones.","metadata":{"cell_id":"fd5512e5-80d1-43cf-9907-50691a1a84a9"}},{"cell_type":"code","metadata":{"cell_id":"c7d1f5ca-fd19-4e85-9913-53ecbefc4c61"},"source":"proc_tok,proc_num = TokenizeProcessor(max_workers=8),NumericalizeProcessor()","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"1b028be2-f829-4db6-9cbe-5bb8d246092a"},"source":"%time ll = label_by_func(sd, lambda x: 0, proc_x = [proc_tok,proc_num])","outputs":[{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "},"metadata":{},"output_type":"display_data"},{"name":"stdout","text":"CPU times: user 22.8 s, sys: 3.4 s, total: 26.2 s\nWall time: 1min 56s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Once the items have been processed they will become list of numbers, we can still access the underlying raw data in `x_obj` (or `y_obj` for the targets, but we don't have any here).","metadata":{"cell_id":"17911e8c-c579-472d-a2ae-6159c226e8d0"}},{"cell_type":"code","metadata":{"cell_id":"5f2877c3-5abe-43ec-a59d-29560ca7b854"},"source":"ll.train.x_obj(0)","outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"'xxbos i grew up on the \\' xxmaj superman ii \\' theatrical version ( \" s2 t \" ) and as a kid , i loved it more than xxmaj part i since not only did it contain more xxmaj superman and three xxmaj superman - type villains , it started off with a bang \\x96 the best xxmaj clark xxmaj kent to xxmaj superman transformations and rescue scenes . xxmaj kids no longer had to impatiently wait for xxmaj superman to appear on screen , as in part i. xxmaj now as an adult , i can see how the mighty had fallen with s2 t ( xxmaj see : my review . ) i \\'ve always heard of the back - story on how they prematurely and unjustifiably fired the original \\'s director , xxmaj richard xxmaj donner from part ii . ( xxmaj it must have been a rarity back then to film two separate movies simultaneously , now it \\'s common : \\' xxmaj back to the xxmaj future \\' and \\' xxmaj matrix \\' 2 & 3 for example . ) xxmaj unfortunately , after finally seeing the xxmaj richard xxmaj donner xxmaj cut ( or , \" s2rd \" ) i still ca n\\'t fully recommend it . xxmaj gone , was the great xxmaj superman change scene , the entire xxmaj paris rescue , as was the wonderful recap of part i in s2 t \\'s opening . xxmaj in fact , they all but wrote the words : \" xxmaj previously on xxmaj superman \\x85 \" in s2rd . xxmaj the special effects were n\\'t great in either xxmaj part i or s2 t , but s2rd , they were mostly downright laughable \\x96 such as xxmaj lois falling from the xxmaj daily xxmaj planet window . i will admit , some new scenes worked and some they took out were welcomed departures , such as any scene in the \" honeymoon suite . \" xxmaj overall , if you grew up on s2 t as i did , and loved it as a child \\x96 not nitpicking as i do as an adult , you should absolutely see s2rd as it \\'s almost a brand new childhood experience with dozens of new scenes . ( xxmaj spoiler alert ) xxmaj unfortunately , the worst change comes last : gone was also the weird amnesia kiss from s2 t replaced with the exact same ending as \\' i. \\' xxmaj this is not only a lazy , unoriginal copout , it does n\\'t make sense on why xxmaj clark would go back to that diner , if those events never actually happened . xxmaj and will he continue to \" turn back time \" for every confrontation ? xxeos'"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"f94d8c99-f5ed-4645-b02b-def3e40baab6"},"source":"pickle.dump(ll, open(path/'ld.pkl', 'wb'))","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"fa2d03e3-a0c6-417d-a689-438d000e5a9a"},"source":"ll = pickle.load(open(path/'ld.pkl', 'rb'))","outputs":[]},{"cell_type":"markdown","source":"## Batching","metadata":{"cell_id":"8b7f2b0f-4295-485b-9022-3442da545d14"}},{"cell_type":"markdown","source":"We have a bit of work to convert our `LabelList` in a `DataBunch` as we don't just want batches of IMDB reviews. We want to stream through all the texts concatenated. We also have to prepare the targets that are the newt words in the text. All of this is done with the next object called `LM_PreLoader`. At the beginning of each epoch, it'll shuffle the articles (if `shuffle=True`) and create a big stream by concatenating all of them. We divide this big stream in `bs` smaller streams. That we will read in chunks of bptt length.","metadata":{"cell_id":"01d67174-46e0-4ca7-bf49-c0070689d83e"}},{"cell_type":"markdown","source":"[Jump_to lesson 12 video](https://course.fast.ai/videos/?lesson=12&t=5565)","metadata":{"cell_id":"283ca5e4-2062-4d4d-a530-34c1ccc14574"}},{"cell_type":"code","metadata":{"cell_id":"8dd0b1e8-5be3-4562-aad6-577781a1db46"},"source":"# Just using those for illustration purposes, they're not used otherwise.\nfrom IPython.display import display,HTML\nimport pandas as pd","outputs":[]},{"cell_type":"markdown","source":"Let's say our stream is:","metadata":{"cell_id":"0c5677bd-34c9-4d4e-9b29-89cb390e1132"}},{"cell_type":"code","metadata":{"cell_id":"249b95af-6e1a-4e72-aad0-6c17f350df78"},"source":"stream = \"\"\"\nIn this notebook, we will go back over the example of classifying movie reviews we studied in part 1 and dig deeper under the surface. \nFirst we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the Processor used in the data block API.\nThen we will study how we build a language model and train it.\\n\n\"\"\"\ntokens = np.array(tp([stream])[0])","outputs":[{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"cell_id":"49cb90e4-44af-4cf3-8c89-7fc7ba9551e1"},"source":"bs, seq_len = 6, 15\nd_tokens = np.array([tokens[i * seq_len : (i + 1) * seq_len] for i in range(bs)])\ndf = pd.DataFrame(d_tokens)\ndisplay(df)","outputs":[{"data":{"application/vnd.deepnote.dataframe+json":{"variableDetails":{"dataframe":{"0":{"0":"xxbos","1":"\n","2":"xxmaj","3":"in","4":"this","5":"notebook","6":",","7":"we","8":"will","9":"go"},"1":{"0":"classifying","1":"movie","2":"reviews","3":"we","4":"studied","5":"in","6":"part","7":"1","8":"and","9":"dig"},"2":{"0":"\n","1":"xxmaj","2":"first","3":"we","4":"will","5":"look","6":"at","7":"the","8":"processing","9":"steps"},"3":{"0":"numbers","1":"and","2":"how","3":"to","4":"customize","5":"it","6":".","7":"xxmaj","8":"by","9":"doing"},"4":{"0":"another","1":"example","2":"of","3":"the","4":"xxmaj","5":"processor","6":"used","7":"in","8":"the","9":"data"},"5":{"0":"then","1":"we","2":"will","3":"study","4":"how","5":"we","6":"build","7":"a","8":"language","9":"model"}},"columns":[{"name":"0","stats":{"count":6,"unique":6,"top":"then","freq":1,"nan_count":0}},{"name":"1","stats":{"count":6,"unique":6,"top":"and","freq":1,"nan_count":0}},{"name":"2","stats":{"count":6,"unique":6,"top":"reviews","freq":1,"nan_count":0}},{"name":"3","stats":{"count":6,"unique":5,"top":"we","freq":2,"nan_count":0}},{"name":"4","stats":{"count":6,"unique":6,"top":"how","freq":1,"nan_count":0}},{"name":"5","stats":{"count":6,"unique":6,"top":"notebook","freq":1,"nan_count":0}},{"name":"6","stats":{"count":6,"unique":6,"top":"part","freq":1,"nan_count":0}},{"name":"7","stats":{"count":6,"unique":6,"top":"xxmaj","freq":1,"nan_count":0}},{"name":"8","stats":{"count":6,"unique":6,"top":"and","freq":1,"nan_count":0}},{"name":"9","stats":{"count":6,"unique":6,"top":"doing","freq":1,"nan_count":0}}],"frequencyInfo":[{"frequencyData":[{"name":"xxbos","frequency":0.16666666666666666},{"name":"classifying","frequency":0.16666666666666666},{"name":"4 others","frequency":0.6666666666666666}],"type":"freq"},{"frequencyData":[{"name":"\n","frequency":0.16666666666666666},{"name":"movie","frequency":0.16666666666666666},{"name":"4 others","frequency":0.6666666666666666}],"type":"freq"},{"frequencyData":[{"name":"xxmaj","frequency":0.16666666666666666},{"name":"reviews","frequency":0.16666666666666666},{"name":"4 others","frequency":0.6666666666666666}],"type":"freq"},{"frequencyData":[{"name":"we","frequency":0.3333333333333333},{"name":"in","frequency":0.16666666666666666},{"name":"3 others","frequency":0.5}],"type":"freq"},{"frequencyData":[{"name":"this","frequency":0.16666666666666666},{"name":"studied","frequency":0.16666666666666666},{"name":"4 others","frequency":0.6666666666666666}],"type":"freq"},{"frequencyData":[{"name":"notebook","frequency":0.16666666666666666},{"name":"in","frequency":0.16666666666666666},{"name":"4 others","frequency":0.6666666666666666}],"type":"freq"},{"frequencyData":[{"name":",","frequency":0.16666666666666666},{"name":"part","frequency":0.16666666666666666},{"name":"4 others","frequency":0.6666666666666666}],"type":"freq"},{"frequencyData":[{"name":"we","frequency":0.16666666666666666},{"name":"1","frequency":0.16666666666666666},{"name":"4 others","frequency":0.6666666666666666}],"type":"freq"},{"frequencyData":[{"name":"will","frequency":0.16666666666666666},{"name":"and","frequency":0.16666666666666666},{"name":"4 others","frequency":0.6666666666666666}],"type":"freq"},{"frequencyData":[{"name":"go","frequency":0.16666666666666666},{"name":"dig","frequency":0.16666666666666666},{"name":"4 others","frequency":0.6666666666666666}],"type":"freq"}]},"numElements":6,"numColumns":15},"text/plain":"            0        1        2      3          4          5      6      7   \\\n0        xxbos       \\n    xxmaj     in       this   notebook      ,     we   \n1  classifying    movie  reviews     we    studied         in   part      1   \n2           \\n    xxmaj    first     we       will       look     at    the   \n3      numbers      and      how     to  customize         it      .  xxmaj   \n4      another  example       of    the      xxmaj  processor   used     in   \n5         then       we     will  study        how         we  build      a   \n\n           8      9          10     11       12       13     14  \n0        will     go       back   over      the  example     of  \n1         and    dig     deeper  under      the  surface      .  \n2  processing  steps  necessary     to  convert     text   into  \n3          by  doing       this      ,       we      'll   have  \n4         the   data      block    api        .       \\n  xxmaj  \n5    language  model        and  train       it        .   \\n\\n  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>xxbos</td>\n      <td>\\n</td>\n      <td>xxmaj</td>\n      <td>in</td>\n      <td>this</td>\n      <td>notebook</td>\n      <td>,</td>\n      <td>we</td>\n      <td>will</td>\n      <td>go</td>\n      <td>back</td>\n      <td>over</td>\n      <td>the</td>\n      <td>example</td>\n      <td>of</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>classifying</td>\n      <td>movie</td>\n      <td>reviews</td>\n      <td>we</td>\n      <td>studied</td>\n      <td>in</td>\n      <td>part</td>\n      <td>1</td>\n      <td>and</td>\n      <td>dig</td>\n      <td>deeper</td>\n      <td>under</td>\n      <td>the</td>\n      <td>surface</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\n</td>\n      <td>xxmaj</td>\n      <td>first</td>\n      <td>we</td>\n      <td>will</td>\n      <td>look</td>\n      <td>at</td>\n      <td>the</td>\n      <td>processing</td>\n      <td>steps</td>\n      <td>necessary</td>\n      <td>to</td>\n      <td>convert</td>\n      <td>text</td>\n      <td>into</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>numbers</td>\n      <td>and</td>\n      <td>how</td>\n      <td>to</td>\n      <td>customize</td>\n      <td>it</td>\n      <td>.</td>\n      <td>xxmaj</td>\n      <td>by</td>\n      <td>doing</td>\n      <td>this</td>\n      <td>,</td>\n      <td>we</td>\n      <td>'ll</td>\n      <td>have</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>another</td>\n      <td>example</td>\n      <td>of</td>\n      <td>the</td>\n      <td>xxmaj</td>\n      <td>processor</td>\n      <td>used</td>\n      <td>in</td>\n      <td>the</td>\n      <td>data</td>\n      <td>block</td>\n      <td>api</td>\n      <td>.</td>\n      <td>\\n</td>\n      <td>xxmaj</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>then</td>\n      <td>we</td>\n      <td>will</td>\n      <td>study</td>\n      <td>how</td>\n      <td>we</td>\n      <td>build</td>\n      <td>a</td>\n      <td>language</td>\n      <td>model</td>\n      <td>and</td>\n      <td>train</td>\n      <td>it</td>\n      <td>.</td>\n      <td>\\n\\n</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"output_type":"display_data"}]},{"cell_type":"markdown","source":"Then if we have a `bptt` of 5, we would go over those three batches.","metadata":{"cell_id":"e2a8a869-8fb3-40cb-a712-3a6ddf9238fe"}},{"cell_type":"code","metadata":{"cell_id":"357f9dd2-1b7a-4c88-bc93-f943d893f36e"},"source":"bs, bptt = 6, 5\n\nfor k in range(3):\n    d_tokens = np.array([tokens[i * seq_len + k * bptt : i * seq_len + (k + 1) * bptt] for i in range(bs)])\n    df = pd.DataFrame(d_tokens)\n    display(HTML(df.to_html(index=True, header=False)))","outputs":[{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>xxbos</td>\n      <td>\\n</td>\n      <td>xxmaj</td>\n      <td>in</td>\n      <td>this</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>classifying</td>\n      <td>movie</td>\n      <td>reviews</td>\n      <td>we</td>\n      <td>studied</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\n</td>\n      <td>xxmaj</td>\n      <td>first</td>\n      <td>we</td>\n      <td>will</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>numbers</td>\n      <td>and</td>\n      <td>how</td>\n      <td>to</td>\n      <td>customize</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>another</td>\n      <td>example</td>\n      <td>of</td>\n      <td>the</td>\n      <td>xxmaj</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>then</td>\n      <td>we</td>\n      <td>will</td>\n      <td>study</td>\n      <td>how</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>notebook</td>\n      <td>,</td>\n      <td>we</td>\n      <td>will</td>\n      <td>go</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>in</td>\n      <td>part</td>\n      <td>1</td>\n      <td>and</td>\n      <td>dig</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>look</td>\n      <td>at</td>\n      <td>the</td>\n      <td>processing</td>\n      <td>steps</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>it</td>\n      <td>.</td>\n      <td>xxmaj</td>\n      <td>by</td>\n      <td>doing</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>processor</td>\n      <td>used</td>\n      <td>in</td>\n      <td>the</td>\n      <td>data</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>we</td>\n      <td>build</td>\n      <td>a</td>\n      <td>language</td>\n      <td>model</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>back</td>\n      <td>over</td>\n      <td>the</td>\n      <td>example</td>\n      <td>of</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>deeper</td>\n      <td>under</td>\n      <td>the</td>\n      <td>surface</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>necessary</td>\n      <td>to</td>\n      <td>convert</td>\n      <td>text</td>\n      <td>into</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>this</td>\n      <td>,</td>\n      <td>we</td>\n      <td>'ll</td>\n      <td>have</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>block</td>\n      <td>api</td>\n      <td>.</td>\n      <td>\\n</td>\n      <td>xxmaj</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>and</td>\n      <td>train</td>\n      <td>it</td>\n      <td>.</td>\n      <td>\\n\\n</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"cell_id":"1523d03a-eb50-4830-b359-dac23a76b5c8"},"source":"#export\nclass LM_Preloader():\n    def __init__(self, data, bs=64, bptt=70, shuffle=False):\n        self.data = data\n        self.bs = bs\n        self.bptt = bptt\n        self.shuffle = shuffle\n        total_len = sum([len(text) for text in data.x])\n        self.n_batch = total_len // bs\n        self.batchify()\n    \n    def __len__(self):\n        return ((self.n_batch - 1) // self.bptt) * self.bs\n    def __getitem__(self, idx):\n        source = self.batched_data[idx % self.bs]\n        seq_idx = (idx // self.bs) * self.bptt\n        return source[seq_idx : seq_idx + self.bptt], source[seq_idx + 1 : seq_idx + 1 + self.bptt]\n    def batchify(self):\n        texts = self.data.x\n        if self.shuffle:\n            texts = texts[torch.randperm(len(texts))]\n        stream = torch.cat([torch.tensor(t) for t in texts])\n        self.batched_data = stream[:self.n_batch * self.bs].view(self.bs, self.n_batch)","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"277f6836-2732-4c6f-9126-c1fc4b171a37"},"source":"dl = DataLoader(LM_Preloader(ll.valid, shuffle=True), batch_size=64)","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"81c01e0b-4958-474b-a822-6016f5125390"},"source":"iter_dl = iter(dl)\nx1,y1 = next(iter_dl)\nx2,y2 = next(iter_dl)","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"3f490618-39c6-45d8-b871-c7388aa94da2"},"source":"x1.size(), y1.size()","outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"(torch.Size([64, 70]), torch.Size([64, 70]))"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"732aeb7b-116c-42f4-a1e2-c9d4ce90d39c"},"source":"vocab = proc_num.vocab","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"89941c30-9179-44bc-99b1-bb6ab0f9dc4e"},"source":"\" \".join(vocab[o] for o in x1[0])","outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"'xxbos xxmaj this film is poorly cast , directed even worse and you would do well to spend your money sitting in the lobby eating popcorn . xxmaj it should be a romantic farce . xxmaj instead attempts to make it sincere , deep and touching are misguided , poorly executed and immature film - making at its worst . xxmaj the xxmaj four xxmaj last xxmaj songs do not'"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"001e7f3d-6430-41d6-87ac-67acd67a3fdf"},"source":"\" \".join(vocab[o] for o in y1[0])","outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"'xxmaj this film is poorly cast , directed even worse and you would do well to spend your money sitting in the lobby eating popcorn . xxmaj it should be a romantic farce . xxmaj instead attempts to make it sincere , deep and touching are misguided , poorly executed and immature film - making at its worst . xxmaj the xxmaj four xxmaj last xxmaj songs do not enter'"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"07031338-b43b-4cd0-bf43-68b460d6177f"},"source":"\" \".join(vocab[o] for o in x2[0])","outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"'enter into the presented theme if there is an attempt to bring out a theme , and perhaps that is its greatest flaw : what was this about - wife vs muse , father / daughter , ex patriots adrift , brothers in jeopardy ? xxmaj or just poor cinematography in a beautiful location . xxmaj it appears to be an xxmaj american version of an xxmaj european melodrama by'"},"metadata":{}}]},{"cell_type":"markdown","source":"And let's prepare some convenience function to do this quickly.","metadata":{"cell_id":"8d12235e-3955-4ee0-9e52-e82d63bf13c9"}},{"cell_type":"code","metadata":{"cell_id":"64d2cd0f-2c0e-45ad-af8b-f440a58ff419"},"source":"#export\ndef get_lm_dls(train_ds, valid_ds, bs, bptt, **kwargs):\n    return (DataLoader(LM_Preloader(train_ds, bs, bptt, shuffle=True), batch_size=bs, **kwargs),\n            DataLoader(LM_Preloader(valid_ds, bs, bptt, shuffle=False), batch_size=2*bs, **kwargs))\n\ndef lm_databunchify(sd, bs, bptt, **kwargs):\n    return DataBunch(*get_lm_dls(sd.train, sd.valid, bs, bptt, **kwargs))","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"65564382-c7e6-4efe-89fe-e06365c8f2eb"},"source":"bs,bptt = 64,70\ndata = lm_databunchify(ll, bs, bptt)","outputs":[]},{"cell_type":"markdown","source":"## Batching for classification","metadata":{"cell_id":"90ebed7c-cb9b-4317-bf51-a4a2a441b514"}},{"cell_type":"markdown","source":"When we will want to tackle classification, gathering the data will be a bit different: first we will label our texts with the folder they come from, and then we will need to apply padding to batch them together. To avoid mixing very long texts with very short ones, we will also use `Sampler` to sort (with a bit of randomness for the training set) our samples by length.\n\nFirst the data block API calls shold look familiar.","metadata":{"cell_id":"632775fa-3f0a-422e-b02c-21b0183aedbb"}},{"cell_type":"markdown","source":"[Jump_to lesson 12 video](https://course.fast.ai/videos/?lesson=12&t=5877)","metadata":{"cell_id":"5f8d31ea-5694-4acc-9f51-509aa14bf282"}},{"cell_type":"code","metadata":{"cell_id":"0b291d19-2dc9-4051-ac3c-1891aaf76a75"},"source":"proc_cat = CategoryProcessor()","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"351b8565-f0f4-412d-9c97-1e560de2e8dc"},"source":"il = TextList.from_files(path, include=['train', 'test'])\nsd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='test'))\nll = label_by_func(sd, parent_labeler, proc_x = [proc_tok, proc_num], proc_y=proc_cat)","outputs":[{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"cell_id":"87bee507-97ed-4389-a166-58243bc61033"},"source":"pickle.dump(ll, open(path/'ll_clas.pkl', 'wb'))","outputs":[]},{"cell_type":"code","metadata":{"cell_id":"01ae7e0f-8a6e-4c51-a86f-b848d857ac61"},"source":"ll = pickle.load(open(path/'ll_clas.pkl', 'rb'))","outputs":[]},{"cell_type":"markdown","source":"Let's check the labels seem consistent with the texts.","metadata":{"cell_id":"af651d3a-1ab8-452d-81cd-9c37573edbc8"}},{"cell_type":"code","metadata":{"cell_id":"11641da6-bf0c-4806-8161-25021093d143"},"source":"[(ll.train.x_obj(i), ll.train.y_obj(i)) for i in [1,12552]]","outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"[('xxbos xxmaj warning : xxmaj avoid this super duper awful movie ... if you watched it you will be s xxrep 9 o disappointed . \\n\\n xxmaj pam and xxmaj denise are grandma age now what are they doing ? xxmaj trying so hard to be young innocent and sexy , just not working at all . xxmaj pam and xxmaj denise act so horribly in this movie . \\n\\n xxmaj plus xxmaj the script is absolutely atrocious , i ca n\\'t believe someone can came out with such crappy ideas . xxmaj with the development of movie industry , movie lovers are not as easy to satisfy as the ones in the last century . i bet the movie goers from last century will hate this too . \\n\\n xxmaj stay away from it . i think watch \" xxmaj white xxmaj chicks \" from 2004 it \\'s so much better that this ... make no mistake at that time i thought that \\'s the worst movie i have ever seen . xxeos',\n  'neg'),\n (\"xxbos i love this show , it 's sure to be a winner . xxmaj jessica xxmaj alba does a great job , it 's about time we have a kick - ass girl who 's not the cutesy type . xxmaj the entire cast is wonderful and all the xxunk have good plots . xxmaj everything is layed out well , and thought over . xxmaj to put it together must have taken a while , because it was n't someone in a hurry that just slapped something together . xxmaj it 's a great show altogether . xxeos\",\n  'pos')]"},"metadata":{}}]},{"cell_type":"markdown","source":"We saw samplers in notebook 03. For the validation set, we will simply sort the samples by length, and we begin with the longest ones for memory reasons (it's better to always have the biggest tensors first).","metadata":{"cell_id":"725608ba-6afd-4318-adcf-f2908cf37b31"}},{"cell_type":"code","metadata":{"cell_id":"30cd62f1-cddc-4c64-8230-d24b045f0dae"},"source":"#export\nfrom torch.utils.data import Sampler\n\nclass SortSampler(Sampler):\n    def __init__(self, data_source, key):\n        self.data_source = data_source\n        self.key = key\n    def __len__(self):\n        return len(self.data_source)\n    def __iter__(self):\n        return iter(sorted(list(range(len(self.data_source))), key=self.key, reversed=True))","outputs":[]},{"cell_type":"markdown","source":"For the training set, we want some kind of randomness on top of this. So first, we shuffle the texts and build megabatches of size `50 * bs`. We sort those megabatches by length before splitting them in 50 minibatches. That way we will have randomized batches of roughly the same length.\n\nThen we make sure to have the biggest batch first and shuffle the order of the other batches. We also make sure the last batch stays at the end because its size is probably lower than batch size.","metadata":{"cell_id":"a4a4c66f-af3c-4987-8f18-e804cfb24463"}},{"cell_type":"code","metadata":{"cell_id":"3167f2aa-0bb5-4fcb-8a6b-e29ba0d646b2"},"source":"#export\nclass SortishSampler(Sampler):\n    def __init__(self, data_source, key, bs):\n        self.data_source,self.key,self.bs = data_source,key,bs\n\n    def __len__(self) -> int: return len(self.data_source)\n\n    def __iter__(self):\n        idxs = torch.randperm(len(self.data_source))\n        megabatches = [idxs[i:i+self.bs*50] for i in range(0, len(idxs), self.bs*50)]\n        sorted_idx = torch.cat([tensor(sorted(s, key=self.key, reverse=True)) for s in megabatches])\n        batches = [sorted_idx[i:i+self.bs] for i in range(0, len(sorted_idx), self.bs)]\n        max_idx = torch.argmax(tensor([self.key(ck[0]) for ck in batches]))  # find the chunk with the largest key,\n        batches[0],batches[max_idx] = batches[max_idx],batches[0]            # then make sure it goes first.\n        batch_idxs = torch.randperm(len(batches)-2)\n        sorted_idx = torch.cat([batches[i+1] for i in batch_idxs]) if len(batches) > 1 else LongTensor([])\n        sorted_idx = torch.cat([batches[0], sorted_idx, batches[-1]])\n        return iter(sorted_idx)","outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"bfb24ed1-8a22-4ab7-9193-2dfa4062ea5f"},"source":"Padding: we had the padding token (that as an id of 1) at the end of each sequence to make them all the same size when batching them. Note that we need padding at the end to be able to use `PyTorch` convenience functions that will let us ignore that padding (see 12c)."},{"cell_type":"code","source":"#export\n\ndef pad_collate(samples, pad_idx=1, pad_first=False):\n    max_len = max([len(s[0]) for s in samples])\n    res = torch.zeros(len(samples), max_len).long() + pad_idx\n    for i,s in enumerate(samples):\n        if pad_first: res[i, -len(s[0]):] = LongTensor(s[0])\n        else:         res[i, :len(s[0]) ] = LongTensor(s[0])\n    return res, tensor([s[1] for s in samples])","metadata":{"tags":[],"cell_id":"b4e7986d-bdf2-4192-8b13-e5c6b5fa5b4c"},"outputs":[]},{"cell_type":"code","source":"bs = 64\ntrain_sampler = SortishSampler(ll.train.x, key=lambda t: len(ll.train[int(t)][0]), bs=bs)\ntrain_dl = DataLoader(ll.train, batch_size=bs, sampler=train_sampler, collate_fn=pad_collate)","metadata":{"tags":[],"cell_id":"eefc48c0-0369-4c21-9b78-8efdf36d4d5d"},"outputs":[]},{"cell_type":"code","source":"iter_dl = iter(train_dl)\nx,y = next(iter_dl)","metadata":{"tags":[],"cell_id":"330ef33c-a38d-40b7-a6a5-4ad604ea3e7e"},"outputs":[]},{"cell_type":"code","source":"lengths = []\nfor i in range(x.size(0)): lengths.append(x.size(1) - (x[i]==1).sum().item())\nlengths[:5], lengths[-1]","metadata":{"tags":[],"cell_id":"cb0a91ad-131a-4f61-892c-306225565f8a"},"outputs":[{"output_type":"execute_result","execution_count":70,"data":{"text/plain":"([3311, 1521, 1486, 1390, 1369], 1001)"},"metadata":{}}]},{"cell_type":"code","source":"#export\ndef get_clas_dls(train_ds, valid_ds, bs, **kwargs):\n    train_sampler = SortishSampler(train_ds.x, key=lambda t: len(train_ds.x[t]), bs=bs)\n    valid_sampler = SortSampler(valid_ds.x, key=lambda t: len(valid_ds.x[t]))\n    return (DataLoader(train_ds, batch_size=bs, sampler=train_sampler, collate_fn=pad_collate, **kwargs),\n            DataLoader(valid_ds, batch_size=bs*2, sampler=valid_sampler, collate_fn=pad_collate, **kwargs))\n\ndef clas_databunchify(sd, bs, **kwargs):\n    return DataBunch(*get_clas_dls(sd.train, sd.valid, bs, **kwargs))","metadata":{"tags":[],"cell_id":"4cd99108-a614-4fcf-be93-74785357d5ff"},"outputs":[]},{"cell_type":"markdown","metadata":{"tags":[],"cell_id":"2606ec27-3796-4dd0-af28-c48f84ce876c"},"source":"# Export"},{"cell_type":"code","outputs":[{"name":"stdout","text":"Converted 12_text.ipynb to exp/nb_12.py\r\n","output_type":"stream"}],"metadata":{"tags":[],"cell_id":"fb90831b-d6a7-461b-a4df-11881b786450"},"source":"!python notebook2script.py 12_text.ipynb"},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"7fb51e7a-7a5a-4079-85a1-03900d2fccd7"},"outputs":[],"execution_count":null}],"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"deepnote_notebook_id":"0b1c191a-df1e-4773-a1c4-7cd348910064","deepnote_execution_queue":[]}}